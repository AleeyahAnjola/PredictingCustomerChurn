{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importint numpy and panda library\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\n\n# loading the data set\nsprint_read = pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T21:13:13.864786Z","iopub.execute_input":"2023-10-01T21:13:13.865277Z","iopub.status.idle":"2023-10-01T21:13:13.915556Z","shell.execute_reply.started":"2023-10-01T21:13:13.865242Z","shell.execute_reply":"2023-10-01T21:13:13.914409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Next, we are going to analyze our data set**","metadata":{}},{"cell_type":"code","source":"# exploring the first few rows of the data set\nsprint_read.head()\nsprint_read.tail()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:13:13.917876Z","iopub.execute_input":"2023-10-01T21:13:13.918422Z","iopub.status.idle":"2023-10-01T21:13:13.941162Z","shell.execute_reply.started":"2023-10-01T21:13:13.918391Z","shell.execute_reply":"2023-10-01T21:13:13.939612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reading our data set information**","metadata":{}},{"cell_type":"code","source":"sprint_read.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:13:13.942946Z","iopub.execute_input":"2023-10-01T21:13:13.943335Z","iopub.status.idle":"2023-10-01T21:13:13.966585Z","shell.execute_reply.started":"2023-10-01T21:13:13.943305Z","shell.execute_reply":"2023-10-01T21:13:13.965188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Checking for duplicates**","metadata":{}},{"cell_type":"code","source":"sprint_read.duplicated()\n# the result shows that there are no duplicates in the data seth","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:13:13.967664Z","iopub.execute_input":"2023-10-01T21:13:13.967962Z","iopub.status.idle":"2023-10-01T21:13:13.989772Z","shell.execute_reply.started":"2023-10-01T21:13:13.967938Z","shell.execute_reply":"2023-10-01T21:13:13.988659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Preprocessing & EDA**","metadata":{}},{"cell_type":"code","source":"# Identifying null values in data\nsprint_read.isnull()\n\n# Getting the number of missing records in each column\n\ncheck_missing_values = sprint_read.isnull().sum()\nprint(check_missing_values)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:13:14.193260Z","iopub.execute_input":"2023-10-01T21:13:14.193812Z","iopub.status.idle":"2023-10-01T21:13:14.214461Z","shell.execute_reply.started":"2023-10-01T21:13:14.193773Z","shell.execute_reply":"2023-10-01T21:13:14.213334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Exploratory Data Analysis(EDA)**","metadata":{}},{"cell_type":"code","source":"# using seaborn to create a heatmap to check for missing data\nimport seaborn as sns\nsns.heatmap(sprint_read.isnull(), yticklabels=False, cbar=False, cmap='coolwarm')\n\n# The empty colored heatmap shows that we truly have no missing values in our data set and no null values","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:13:14.216027Z","iopub.execute_input":"2023-10-01T21:13:14.216348Z","iopub.status.idle":"2023-10-01T21:13:14.721048Z","shell.execute_reply.started":"2023-10-01T21:13:14.216323Z","shell.execute_reply":"2023-10-01T21:13:14.719639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\n# Select features and target variable\nX = sprint_read[['MonthlyCharges']]  # Numerical feature\ny = sprint_read['Churn']  # Target variable\n\n# Split the data into training (80%) and testing (20%) sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create a logistic regression model\nmodel = LogisticRegression()\n\n# Train the model on the training data\nmodel.fit(X_train, y_train)\n\n# Make predictions on the testing data\ny_pred = model.predict(X_test)\n\n# Calculate accuracy, precision, and recall\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, pos_label='Yes')\nrecall = recall_score(y_test, y_pred, pos_label='Yes')\n\n# Print the results\nprint(f'Accuracy: {accuracy:.2f}')\nprint(f'Precision: {precision:.2f} (Out of those predicted to leave, how many actually left)')\nprint(f'Recall: {recall:.2f} (Out of those who left, how many were correctly predicted)')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:13:14.722373Z","iopub.execute_input":"2023-10-01T21:13:14.723255Z","iopub.status.idle":"2023-10-01T21:13:14.782695Z","shell.execute_reply.started":"2023-10-01T21:13:14.723225Z","shell.execute_reply":"2023-10-01T21:13:14.781057Z"},"trusted":true},"execution_count":null,"outputs":[]}]}